import React from 'react';
import WatsonSpeech from "watson-speech";

const audioContext = new window.AudioContext();

/**
 * @deprecated
 * Send req, fetch and play text-to-speech result generated by Watson
 * It tries to use ibm-watson sdk
 * so it is adopted from the Synthesize audio example in the official doc
 * but the example is modified to adapt a browser env rather than node.js
 * where the file system manipulation is allowed.
 * When modifying the example, the author is too stupid to find a way to convert
 * the response (arrayBuffer?) to a playable format.
 * This method has potential to work properly if a web expert is found.
 * @see https://cloud.ibm.com/apidocs/text-to-speech?code=node
 */
function requestVoice() {
  const TextToSpeechV1 = require('ibm-watson/text-to-speech/v1');
  const {IamAuthenticator} = require('ibm-watson/auth');

  const textToSpeech = new TextToSpeechV1({
    authenticator: new IamAuthenticator({
      apikey: 'GdjN0agnCaDtkn_1DGLuxxmuQOj7RWmHFbBRF2A8T2OI',
    }),
    serviceUrl: 'https://api.eu-gb.text-to-speech.watson.cloud.ibm.com/instances/8d98ae80-bfdc-4719-85de-3b1a5386ad4b',
  });

  //It is simpler for browser to handle mp3 than wav, a decoding step less
  const synthesizeParams = {
    text: 'Hello world',
    accept: 'audio/mp3',
    voice: 'en-US_AllisonV3Voice',
  };

  textToSpeech.synthesize(synthesizeParams)
    .then(buffer => {
      audioContext.decodeAudioData(buffer).then(data => console.log(data))
    })
    .catch(err => {
      console.log('error:', err);
    });
}


/**
 * @deprecated
 * Send req, fetch and play text-to-speech result generated by Watson
 * It tries to use speech-javascript-sdk to do the job
 * However, the doc of the github repo is ood,
 * e.g. the step of setting up a server (./examples/readme.md) contains copy-and-paste error
 * and the referred file is also not existed.
 * The guidance of using .env file is also not clear.
 * The repo is considered deprecated, further considering the fact that the core file (./speech-to-text)
 * is updated on June but the latest change of the service is on July (ref.2 below)
 * @see https://github.com/watson-developer-cloud/speech-javascript-sdk
 * @see https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-release-notes#text-to-speech-31march2022
 */
function requestVoice2() {
  fetch('/api/text-to-speech/token')
    .then(function (response) {
      return response.json();
    })
    .then(function (token) {
      const audio = WatsonSpeech.TextToSpeech.synthesize(Object.assign(token, {
        text: "Hello from IBM",
      }));
      audio.onerror = function (err) {
        console.log('audio error: ', err);
      };
    });
}

/**
 * Create the Audio Context based on broswer type
 * As of Aug 10 2022, there is no plan to support old-fashion browser
 * so the webkitAudioContext() and mozAudioContext() is dropped
 * therefore, it may not compatible with older Firefox and Chrome browsers
 * If there is plan to add support later, just search the function name, example will show up.
 * @returns {AudioContext} Suitable Audio Context Holder
 */
function audioContextCheck() {
  if (typeof AudioContext !== "undefined") {
    return new AudioContext();
  }
}

/**
 * Send req, fetch and play text-to-speech result generated by Watson
 * It directly send a REST api request to the server and decode the audio data
 * TODO deprecated method btoa is used
 * TODO nobody can understand the heart-stopping nested then() here
 * TODO change the text-to-speech in quantum.html
 */
function requestVoice3() {
  var audioContext = audioContextCheck();
  var audioBuffer;


  fetch('https://api.eu-gb.text-to-speech.watson.cloud.ibm.com/instances/8d98ae80-bfdc-4719-85de-3b1a5386ad4b/v1/synthesize?text=Our%20Successful%20Stories&voice=en-US_MichaelV3Voice', {
    headers: {
      'Accept': 'audio/wav',
      'Authorization': 'Basic ' + btoa('apikey:GdjN0agnCaDtkn_1DGLuxxmuQOj7RWmHFbBRF2A8T2OI')
    }
  }).then(r => {
    console.log(r.body)
    r.arrayBuffer().then(
      r => audioContext.decodeAudioData(r).then(
        data => {
          audioBuffer = data
          const playSound = audioContext.createBufferSource();
          playSound.buffer = audioBuffer;
          playSound.connect(audioContext.destination);
          playSound.start(audioContext.currentTime);
        }))

  });
}

/**
 * The default React Export is a button playing voice
 * Just use the js function above directly if you like to custom the UI
 */
class TextToSpeech extends React.Component {
  render() {
    return (
      <button onClick={requestVoice3}>Play Voice</button>
    )
  }
}

export default TextToSpeech
